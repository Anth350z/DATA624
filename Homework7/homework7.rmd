---
title: 'Data 624 - Homework #7'
author: "Paul Britton"
date: '2020-04-05'
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    toc_collapsed: true
toc_depth: 3
number_sections: true
theme: lumen
---


Exercises 6.3  from the K&J book. 
The rpubs version of this work can be found [here](https://rpubs.com/plb_lttfer/595176), and source/data can be found on github [here](https://github.com/plb2018/DATA624/tree/master/Homework7).
 
 
```{r load.requirements, warning = FALSE, message = FALSE}
#clear the workspace
rm(list = ls())

#load req's packages
library(AppliedPredictiveModeling)
library(caret)
library(elasticnet)
library(knitr)
library(ggplot2)

```


## Question 6.3

A chemical manufacturing process for a pharmaceutical product was discussed in Sect. 1.4. In this problem, the objective is to understand the relationship between biological measurements of the raw materials (predictors), 6.5 Computing 139
measurements of the manufacturing process (predictors), and the response of
product yield. Biological predictors cannot be changed but can be used to
assess the quality of the raw material before processing. On the other hand,
manufacturing process predictors can be changed in the manufacturing process.
Improving product yield by 1% will boost revenue by approximately
one hundred thousand dollars per batch:


### a) Start R and use these commands to load the data:

```{r}
data(ChemicalManufacturingProcess)

chem <- ChemicalManufacturingProcess

head(chem)

```

The matrix processPredictors contains the 57 predictors (12 describing
the input biological material and 45 describing the process predictors)
for the 176 manufacturing runs. yield contains the percent yield for each
run.

### b) A small percentage of cells in the predictor set contain missing values. Use an imputation function to fill in these missing values (e.g., see Sect. 3.8).

For this I used caret::preprocess as was mentioned in the book.  The data are relatively obscure and leave little room for intuition as to the "best" method for imputation so I went with KNN.

```{r}
#impute using knn
chem.imp <- preProcess(chem[,2:ncol(chem)], method=c('knnImpute'))
chem <- cbind(chem$Yield,predict(chem.imp, chem[,2:ncol(chem)]))
colnames(chem)[1] <- "Yield"

```


### c) Split the data into a training and a test set, pre-process the data, and tune a model of your choice from this chapter. What is the optimal value of the performance metric?

First we split the data into test and training sets.  I've gone with 70/30, which is somewhat arbitrary.

```{r}
set.seed(11)

#split 70/30
n <-  floor(0.70 * nrow(chem))
idx <- sample(seq_len(nrow(chem)), size = n)
train <- chem[idx, ]
test <- chem[-idx, ]

```

I used caret to run an elastic-net model with a 20-step tuning range from 0-1 by 0.05 for both "lambda" and "fraction".  5-fold cross validation was also used as part of the training process.


```{r}
#train the model
enet.model <-  train(x=train[,-1],
                 y=train$Yield,
                 method='enet',
                 metric='RMSE',
                 tuneGrid=expand.grid(.fraction = seq(0, 1, by=0.05), 
                                      .lambda = seq(0, 1, by=0.05)),
                 trControl=trainControl(method='cv',number=5),
                 preProcess=c('center','scale'))
plot(enet.model)

#best params
enet.model$bestTune

#perf of best params
getTrainPerf(enet.model)

```

The optimal parameters were fraction = `r enet.model$bestTune[[1]]` and lambda = `r enet.model$bestTune[[2]]` with an RMSE of `r getTrainPerf(enet.model)[[1]]` and an R-squared of  `r getTrainPerf(enet.model)[[2]]` 



### d) Predict the response for the test set.What is the value of the performance metric and how does this compare with the resampled performance metric on the training set?

```{r}
#apply the trained model
enet.pred <- predict(enet.model, newdata=test[,-1])
output <- postResample(pred=enet.pred, obs=test$Yield)
kable(output)
```

The RMSE is higher than the training set and the R2 is lower.  This is expected as out-sample model performance is almost never as good as in-sample.


### e) Which predictors are most important in the model you have trained? Do either the biological or process predictors dominate the list?

```{r}

#get all the coefficients
enet.model.coeff <- predict.enet(enet.model$finalModel, s=enet.model$bestTune[1, "fraction"], type="coef", mode="fraction")$coefficients

#drop the zeros and format
enet.model.coeff <- data.frame(sort(enet.model.coeff[enet.model.coeff != 0 ]))
colnames(enet.model.coeff) <- c("Coefficient")

#output
kable(enet.model.coeff)

```

It appears as though Manufacturing Processes dominate the list with process 32 & 13 being the strongest - one with a positive and one with a negative relationship.  Of the 14 non-zero coefficients, we see that 10 are manufacturing related and 4 are biological.  We also see that the top-5 coefficients are manufacturing as opposed to biological.



### f) Explore the relationships between each of the top predictors and the response. How could this information be helpful in improving yield in future runs of the manufacturing process?

We'll focus on the top 5 predictors for this part.

```{r}

#extract the top 5
exp <- chem[,c("Yield",
               "ManufacturingProcess32",
               "ManufacturingProcess13",
               "ManufacturingProcess36",
               "ManufacturingProcess17",
               "ManufacturingProcess09")]


kable(head(exp,5))


pairs(exp)


```

If taken the top 5 predictors and plotted them as a "pairs" plot in order to examine the relationships.  A few things:

- Ultimately, our "real world" goal here is to enhance yield as opposed to just creating a good model to predict yield.  In that regard, we may want to reduce exposure to, or elimiate processes with a negative correlation to yield (process 13 and 17... likely 36 also )
- At a minimum, 13 and 17 themselves appear to be correlated to one another.  Perhapse we could drop one of them entirely in the manufacturing process.
- Process 32 and to a lesser extent, process 9, appear to have a positive correlation with Yield.  I'd want amplify my exposure to those processes to the extent possible
- Generally, I'd like to try and figure out WHY the above relationships exist and try to get an intuitive understanding of how to make improvements.






